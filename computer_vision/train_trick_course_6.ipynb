{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlook\n",
    "* Stochastic Depth \n",
    "* Warm up \n",
    "* Label Smoothing \n",
    "* No Bias Weight Decay \n",
    "* Teacher-Student Knowledge Distillation \n",
    "* Mixup \n",
    "* Group Normalization \n",
    "* Weight Standardization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "\n",
    "    def basic_forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if not self.training:\n",
    "            out = self.basic_forward(x)\n",
    "            return out\n",
    "        else:\n",
    "            if not self.stochastic_depth:\n",
    "                out = self.basic_forward(x)\n",
    "                return out\n",
    "            else:\n",
    "                actives = torch.bernoulli(self.probability)\n",
    "                if actives == 0:\n",
    "                    print(\"skip\")\n",
    "                    return x\n",
    "                else:\n",
    "                    print(\"run\")\n",
    "                    out = self.basic_forward(x)\n",
    "                    return out\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels, reduction):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1, padding=0)\n",
    "\n",
    "\n",
    "        self.fc2 = nn.Conv2d(\n",
    "            channels // reduction, channels, kernel_size=1, padding=0\n",
    "        )\n",
    "\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "    \n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes,\n",
    "        planes,\n",
    "        groups,\n",
    "        reduction,\n",
    "        stride=1,\n",
    "        downsample=None,\n",
    "        stochastic_depth=True,\n",
    "        probability=torch.tensor(0.8),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.stochastic_depth = stochastic_depth\n",
    "        self.probability = probability\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes * 2,\n",
    "            planes * 4,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes, kernel_size=1, bias=False)\n",
    "\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "        self.se_module = SEModule(\n",
    "            planes,\n",
    "            reduction=reduction,)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SEBottleneck(32, 32, 1, 4).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip\n"
     ]
    }
   ],
   "source": [
    "input_features = torch.randn(4, 32, 32, 32)\n",
    "ouptut = model(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8021000027656555\n"
     ]
    }
   ],
   "source": [
    "# bernoulli\n",
    "value = 0\n",
    "count = 10000\n",
    "for _ in range(count):\n",
    "    value += torch.bernoulli(torch.tensor(0.8))\n",
    "print((value / count).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warm up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "## modify from source : https://github.com/Tony-Y/pytorch_warmup#radam-warmup\n",
    "\n",
    "\n",
    "class BaseWarmup:\n",
    "    \"\"\"Base class for all warmup schedules\n",
    "    Arguments:\n",
    "        optimizer (Optimizer): an instance of a subclass of Optimizer\n",
    "        warmup_params (list): warmup paramters\n",
    "        last_step (int): The index of last step. (Default: -1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer: Optimizer, warmup_params, last_step=-1):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_params = warmup_params\n",
    "        self.last_step = last_step\n",
    "        self.step()\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"Returns the state of the warmup scheduler as a :class:`dict`.\n",
    "        It contains an entry for every variable in self.__dict__ which\n",
    "        is not the optimizer.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            key: value for key, value in self.__dict__.items() if key != \"optimizer\"\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        \"\"\"Loads the warmup scheduler's state.\n",
    "        Arguments:\n",
    "            state_dict (dict): warmup scheduler state. Should be an object returned\n",
    "                from a call to :meth:`state_dict`.\n",
    "        \"\"\"\n",
    "        self.__dict__.update(state_dict)\n",
    "\n",
    "    def step(self, step=None):\n",
    "        \"\"\"Dampen the learning rates.\n",
    "        Arguments:\n",
    "            step (int): The index of current step. (Default: None)\n",
    "        \"\"\"\n",
    "        if step is None:\n",
    "            step = self.last_step + 1\n",
    "        self.last_step = step\n",
    "\n",
    "        for group, params in zip(self.optimizer.param_groups, self.warmup_params):\n",
    "            omega = self.warmup_factor(step, **params)\n",
    "            group[\"lr\"] *= omega\n",
    "\n",
    "    def warmup_factor(self, step, **params):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class ExponentialWarmup(BaseWarmup):\n",
    "    \"\"\"Exponential warmup schedule.\n",
    "    Arguments:\n",
    "        optimizer (Optimizer): an instance of a subclass of Optimizer\n",
    "        warmup_period (int or list): Effective warmup period\n",
    "        last_step (int): The index of last step. (Default: -1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, warmup_period, last_step=-1):\n",
    "        group_count = len(optimizer.param_groups)\n",
    "        warmup_params = [dict(warmup_period=warmup_period) for _ in range(group_count)]\n",
    "        super().__init__(optimizer, warmup_params, last_step)\n",
    "\n",
    "    def warmup_factor(self, step, warmup_period):\n",
    "        return 1.0 - math.exp(-(step + 1) / warmup_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torch import optim\n",
    "model = models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 1000\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_steps)\n",
    "warmup_scheduler = ExponentialWarmup(optimizer, warmup_period=num_steps // 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeff.yang/opt/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/Users/jeff.yang/opt/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_ = []\n",
    "for _ in range(num_steps):\n",
    "    lr_scheduler.step(lr_scheduler.last_epoch + 1)\n",
    "    warmup_scheduler.step()\n",
    "    lr_.append(optimizer.param_groups[0][\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lr_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import numpy as np\n",
    "\n",
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, classes: int, smoothing: float = 0.1):\n",
    "        super().__init__()\n",
    "        assert 0 <= smoothing < 1\n",
    "        if not smoothing:\n",
    "            self.criterion_entropy = nn.CrossEntropyLoss()\n",
    "            print(\"Deactivated smoothing, apply CrossEntropyLoss.\")\n",
    "        else:\n",
    "            self.criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "            print(\"Activated smoothing, apply KLDivLoss.\")\n",
    "\n",
    "        self.classes = classes\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1 - smoothing\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def convert_label_to_smooth(self, true_labels: torch.Tensor):\n",
    "        label_shape = torch.Size((true_labels.size(0), self.classes))\n",
    "        true_dist = torch.empty(size=label_shape, device=true_labels.device)\n",
    "        true_dist.fill_(self.smoothing / (self.classes - 1))\n",
    "        true_dist = true_dist.scatter_(1, true_labels.data, self.confidence)\n",
    "        return true_dist\n",
    "\n",
    "    def forward(\n",
    "        self, prediction: torch.Tensor, true_labels: Union[np.ndarray, torch.Tensor]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        prediction  -> shape == [batch, self.classes]\n",
    "        true_labels -> shape == [batch, 1]\n",
    "        \"\"\"\n",
    "        if prediction.shape[1] != self.classes:\n",
    "            raise ValueError(\n",
    "                f\"Mismatch between prediction and specified class number, have pre-specified classes equal to {self.classes} while {prediction.shape[1]} in prediction\"\n",
    "            )\n",
    "        if not isinstance(true_labels, torch.Tensor):\n",
    "            true_labels = torch.tensor(true_labels, dtype=torch.long)\n",
    "        else:\n",
    "            true_labels = true_labels.type(torch.long)\n",
    "        if self.smoothing:\n",
    "            print(true_labels)\n",
    "            print(\"----------\")\n",
    "            true_labels = self.convert_label_to_smooth(true_labels.reshape(-1, 1))\n",
    "            print(\"convert to smooth\")\n",
    "            print(\"----------\")\n",
    "            print(true_labels)\n",
    "            prediction = prediction.log_softmax(-1)\n",
    "            loss = self.criterion(prediction, true_labels)\n",
    "        else:\n",
    "            loss = self.criterion_entropy(prediction, true_labels.reshape(-1))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activated smoothing, apply KLDivLoss.\n"
     ]
    }
   ],
   "source": [
    "model = LabelSmoothing(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.randn(4, 5)\n",
    "label = torch.tensor([0, 4, 3, 1]).reshape(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [4],\n",
      "        [3],\n",
      "        [1]])\n",
      "----------\n",
      "convert to smooth\n",
      "----------\n",
      "tensor([[0.9000, 0.0250, 0.0250, 0.0250, 0.0250],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.9000],\n",
      "        [0.0250, 0.0250, 0.0250, 0.9000, 0.0250],\n",
      "        [0.0250, 0.9000, 0.0250, 0.0250, 0.0250]])\n"
     ]
    }
   ],
   "source": [
    "loss = model(prediction, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Bias Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weight_decay(net, l2_value, skip_list=[]):\n",
    "    decay, no_decay = [], []\n",
    "    for name, param in net.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue  # skip frozen weights\n",
    "        # skip bias and bn layer\n",
    "        if name.endswith(\".bias\") or (\"_bn\" in name) or (name in skip_list):\n",
    "            no_decay.append(param)\n",
    "        else:\n",
    "            decay.append(param)\n",
    "    return [\n",
    "        {\"params\": no_decay, \"weight_decay\": 0.0},\n",
    "        {\"params\": decay, \"weight_decay\": l2_value},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()\n",
    "parameters = add_weight_decay(model, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters[0][\"weight_decay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters[1][\"weight_decay\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.beta import Beta\n",
    "\n",
    "\n",
    "class Mixup(nn.Module):\n",
    "    def __init__(self, alpha: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.beta = Beta(alpha, alpha)\n",
    "\n",
    "    def __get_mixup_batch(\n",
    "        self, mini_batch_image: torch.Tensor, mini_batch_label: torch.Tensor\n",
    "    ):\n",
    "        lambda_ = self.beta.sample()\n",
    "        batch_size = mini_batch_image.shape[0]\n",
    "        shuffle = torch.randperm(batch_size)\n",
    "        shuffle_mini_batch_x = mini_batch_image[shuffle]\n",
    "        shuffle_mini_batch_y = mini_batch_label[shuffle]\n",
    "        mixup_x = mini_batch_image * lambda_ + (1 - lambda_) * shuffle_mini_batch_x\n",
    "        return (\n",
    "            mixup_x,\n",
    "            mini_batch_label.reshape(-1),\n",
    "            shuffle_mini_batch_y.reshape(-1),\n",
    "            lambda_,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        mini_batch_image: torch.Tensor,\n",
    "        mini_batch_label: torch.Tensor,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        mini_batch_image -> shape == [batch, channel, height, width]\n",
    "        mini_batch_label -> shape == [batch, 1] or [batch]\n",
    "        \"\"\"\n",
    "        (\n",
    "            mixup_x,\n",
    "            mini_batch_label,\n",
    "            shuffle_mini_batch_y,\n",
    "            lambda_,\n",
    "        ) = self.__get_mixup_batch(mini_batch_image, mini_batch_label)\n",
    "        output = model(mixup_x)\n",
    "        loss = self.criterion(output, mini_batch_label) * lambda_ + (\n",
    "            1 - lambda_\n",
    "        ) * self.criterion(output, shuffle_mini_batch_y)\n",
    "        return mixup_x, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Mixup()\n",
    "model = models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_image = torch.cat((torch.ones(3, 3, 64, 64) , torch.zeros(3, 3, 64, 64)), 0)\n",
    "mini_batch_label = torch.tensor([1, 1, 1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_, loss = trainer(model, mini_batch_image, mini_batch_label)\n",
    "for _ in range(6):\n",
    "    plt.subplot(231+_)\n",
    "    plt.title(round((image_[_].mean()).item(), 2))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image_[_].permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teacher-Student Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, temperature: Union[int, float] = 2):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        self.temperature = temperature\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.logsoftmax = nn.LogSoftmax(1)\n",
    "\n",
    "    def forward(self, student_output: torch.Tensor, teacher_output: torch.Tensor):\n",
    "        \"\"\"\n",
    "        student_output -> shape == [batch, class_number]\n",
    "        teacher_output -> shape == [batch, class_number]\n",
    "        \"\"\"\n",
    "\n",
    "        if student_output.shape != teacher_output.shape:\n",
    "            raise ValueError(\n",
    "                f\"Mismatch between student_output and teacher_output, got student_output : {student_output.shape} & teacher_output : {teacher_output.shape} respectively\"\n",
    "            )\n",
    "        student_output = self.logsoftmax(student_output / self.temperature)\n",
    "        teacher_output = self.softmax(teacher_output / self.temperature)\n",
    "\n",
    "        loss = (\n",
    "            self.criterion(student_output, teacher_output)\n",
    "            * self.temperature\n",
    "            * self.temperature\n",
    "        )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "distill = DistillationLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_output = torch.randn(32, 4)\n",
    "teacher_output = torch.randn(32, 4)\n",
    "loss = distill(student_output, teacher_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(nn.Conv2d):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(Conv2d, self).__init__(in_channels, out_channels, kernel_size, stride,\n",
    "                 padding, dilation, groups, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weight = self.weight\n",
    "        weight_mean = weight.mean(dim=1, keepdim=True).mean(dim=2,\n",
    "                                  keepdim=True).mean(dim=3, keepdim=True)\n",
    "        weight = weight - weight_mean\n",
    "        std = weight.view(weight.size(0), -1).std(dim=1).view(-1, 1, 1, 1) + 1e-5\n",
    "        weight = weight / std.expand_as(weight)\n",
    "        return F.conv2d(x, weight, self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv2d(12, 12, 3)\n",
    "output = model(torch.randn(1, 12 ,32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/GN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(16, 10, 32, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_ = dummy_input.mean([0, 2, 3], keepdim=True)\n",
    "std_ = dummy_input.std([0, 2, 3], keepdim=True)\n",
    "normalization = (dummy_input - average_) / std_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 當N group == 1 時, GN == LN, 當 group == C 時, GN == IN\n",
    "n_group = 5\n",
    "dummy_input_copy = dummy_input.clone()\n",
    "b, c, h, w = dummy_input_copy.size()\n",
    "dummy_input_copy = dummy_input_copy.reshape(b, n_group, int(c / n_group), h, w)\n",
    "average_ = dummy_input_copy.mean([2, 3, 4], keepdim=True)\n",
    "std_ = dummy_input_copy.std([2, 3, 4], keepdim=True)\n",
    "normalization = (dummy_input_copy - average_) / std_\n",
    "normalization = normalization.reshape(b, c, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
